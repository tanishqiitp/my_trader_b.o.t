{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac45e9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ki pehli 5 lines:\n",
      "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
      "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
      "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
      "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
      "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
      "\n",
      "   slope   ca  thal  target  \n",
      "0    3.0  0.0   6.0       0  \n",
      "1    2.0  3.0   3.0       1  \n",
      "2    2.0  2.0   7.0       1  \n",
      "3    3.0  0.0   3.0       0  \n",
      "4    1.0  0.0   3.0       0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset from a URL\n",
    "# Is dataset mein 'target' column batata hai ki patient ko heart disease hai (1) ya nahi (0).\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
    "data = pd.read_csv(url, header=None, names=column_names, na_values='?')\n",
    "\n",
    "# Handle missing values by dropping rows with any missing data for simplicity\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Binarize the target variable: values > 0 mean heart disease (1), 0 means no disease (0)\n",
    "data['target'] = (data['target'] > 0).astype(int)\n",
    "\n",
    "\n",
    "# Let's see the first 5 rows of our data\n",
    "print(\"Data ki pehli 5 lines:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e1772d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ke liye data points: 237\n",
      "Testing ke liye data points: 60\n"
     ]
    }
   ],
   "source": [
    "# 'target' column ko chhodkar baaki sab hamare features (X) hain\n",
    "X = data.drop('target', axis=1)\n",
    "\n",
    "# 'target' column hamara output (y) hai\n",
    "y = data['target']\n",
    "\n",
    "# Data ko 80% training aur 20% testing mein baant do\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features for better performance\n",
    "# Isse saare features ek jaise scale par aa jaate hain\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "print(\"\\nTraining ke liye data points:\", X_train.shape[0])\n",
    "print(\"Testing ke liye data points:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c4c32f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model training shuru...\n",
      "Model training poori hui!\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression ka model banate hain\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Model ko training data par sikhate hain (fit karte hain)\n",
    "print(\"\\nModel training shuru...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training poori hui!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "586b5932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model ne yeh weights seekhe hain:\n",
      "age: -0.0667\n",
      "sex: 0.6371\n",
      "cp: 0.3628\n",
      "trestbps: 0.4681\n",
      "chol: 0.3225\n",
      "fbs: -0.4408\n",
      "restecg: 0.2049\n",
      "thalach: -0.4731\n",
      "exang: 0.4317\n",
      "oldpeak: 0.3357\n",
      "slope: 0.2409\n",
      "ca: 1.1399\n",
      "thal: 0.5331\n"
     ]
    }
   ],
   "source": [
    "# Har feature ke liye seekhe gaye weights ko dekhte hain\n",
    "learned_weights = model.coef_[0]\n",
    "feature_names = X.columns\n",
    "\n",
    "print(\"\\nModel ne yeh weights seekhe hain:\")\n",
    "for feature, weight in zip(feature_names, learned_weights):\n",
    "    print(f\"{feature}: {weight:.4f}\")\n",
    "\n",
    "# A positive weight means that feature increases the chance of heart disease.\n",
    "# A negative weight means it decreases the chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fb67612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model ki Accuracy: 86.67%\n"
     ]
    }
   ],
   "source": [
    "# Test data par prediction karte hain\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Model ki accuracy check karte hain\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel ki Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79ffd665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Naye Patient ki Report ---\n",
      "Model ka Faisla: Is patient ko heart disease hone ka khatra nahi hai.\n",
      "Confidence (Probability):\n",
      "  - No Heart Disease (0): 89.66%\n",
      "  - Heart Disease (1): 10.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ertan\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Naye patient ka data (13 features ke hisaab se)\n",
    "# Let's say: age=52, sex=1, cp=2, trestbps=172, chol=199, etc.\n",
    "new_patient_data = [[52, 1, 2, 172, 199, 1, 1, 162, 0, 0.5, 2, 0, 3]]\n",
    "\n",
    "# Important: Naye data ko bhi usi scaler se transform karna hoga\n",
    "new_patient_scaled = scaler.transform(new_patient_data)\n",
    "\n",
    "# Naye patient ke liye prediction karna\n",
    "prediction = model.predict(new_patient_scaled)\n",
    "prediction_probability = model.predict_proba(new_patient_scaled)\n",
    "\n",
    "print(\"\\n--- Naye Patient ki Report ---\")\n",
    "if prediction[0] == 1:\n",
    "    print(\"Model ka Faisla: Is patient ko heart disease hone ka khatra hai.\")\n",
    "else:\n",
    "    print(\"Model ka Faisla: Is patient ko heart disease hone ka khatra nahi hai.\")\n",
    "\n",
    "print(f\"Confidence (Probability):\")\n",
    "print(f\"  - No Heart Disease (0): {prediction_probability[0][0]*100:.2f}%\")\n",
    "print(f\"  - Heart Disease (1): {prediction_probability[0][1]*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
